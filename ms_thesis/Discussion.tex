\documentclass[msthesis.tex]{subfiles}

\begin{document}
\chapter{Discussion}
In this work classification based on a subgraph derived from structural brain connectivity was the major challenge. As mentioned in \autoref{tab:classify_combo}, a large combination of possibilities for designing the classification task was investigated to obtain the most interpretable and statistically significant results. The goal was to not only gain the maximum classification performance but also to design a generalized framework in which each step can be visualized. The architecture remains specific to structural brain connectivity but is generalizable enough to predict different target variables. Major considerations for the task design such as connectivity features and graph structure are explained in the subsequent sections.

\section{Connectivity Metric}
\label{disc:connfe}
This section will discuss in detail the reason for directing the analysis in \autoref{chap:results} towards using the streamline count as a connectivity metric. It will also elucidate the inefficacy of other connectivity features in terms of biological correspondence.   

There were three types of features used as representatives of structural brain connectivity. The number of streamlines, the mean \gls{FA} of streamlines, and the mean streamline length. Generally, the number of streamlines seemed to have performed much better than the other two features considering the \gls{AUC} for classification of gender on an independent test set (\autoref{subsec:Baseline_ana}). It performed better with both baseline and solver based methods, regardless of the labels i.e. personality trait or gender. 

The superior performance of the number of streamlines using the \gls{MEWIS} solver based approach seems plausible due to the incorporation of a particular constraint in the pipeline. A feature from the connectome is included in the input graph for the solver if and only if there is at least one streamline present for all subjects. Such a condition remained unique to the number of streamlines. Perhaps trying such conceptual \textit{a priori} knowledge with the mean \gls{FA} and mean streamline length could yield different results. Furthermore, the streamline count was a biologically coherent measure of brain connectivity as explained in \ref{subsec:Baseline_ana}.

The mean \gls{FA} is a local metric derived from one voxel at a time. Interpolating such a local measure to infer connectivity between brain regions is hence problematic. The mean \gls{FA} is modulated by intra-voxel orientational dispersion, myelination, packaging density, etc. A linear relationship between structural brain connectivity and mean \gls{FA} cannot be established since a change in anisotropy does not necessarily correspond to a change in \gls{FA} \citep{JONES2013239}.

In our analysis, the number of fibers was downsampled from five million to one million by using the \gls{SIFT} algorithm to generate anatomically constrained tractography. This might have caused shorter fibers to be over-represented \citep{smith2015effects}. The non-uniform distribution of the streamline lengths is presented in \cref{fig:hist_zscores}. Other biases in the tractography such as streamline to node assignment make the streamline length an abstract measure connectivity \citep{yeh2020mapping}. 
\section{Constraining the Number of Nodes}
As mentioned in \autoref{method:MEWS}, the \gls{MEWIS} solver implementation was give a constraint to preserve a specified number of nodes in order to indirectly control the number of edges preserved. Without this constraint, an induced subgraph could not be formed and the results produced by the solver could not be compared to the baseline exhaustively. Forming an induced subgraph is of high importance in clinical applications in which brain networks relevant to a disease pathology have to be found. Translating such subgraph based classification from computational models to research practice requires the need to compare the performance with existing methods.

A subgraph $\Tilde{G}(\Tilde{V}, \Tilde{E})$ of $G (V,E)$ is called an induced subgraph if and only if two vertices $u,v$  adjacent in $\Tilde{G}$ are also adjacent in $G(V,E)$. In the implementation of \gls{MEWIS} for this project, induced subgraph is formed by deleting vertices (with the maximal sum of edge weights) but alongside ensuring that the subgraph is connected. 

Without constraining the number of nodes or forming an induced subgraph, the output graph returned from the solver had an arbitrary number of edges based on the original implementation in \cite{DBLP:journals/corr/LobodaAS16}. When the parameter $m$ for specifying the number of nodes was added different output graphs could be generated from the same input graph. These different output graph had a different number of edges on the basis of the number of nodes. All these graphs contained a different number of edges which could be matched to the $k$ percentile of features preserved by the baseline. Hence, the incorporation of the constraint on the number of nodes was pivotal to evaluate the performance of the features selected by the \gls{MEWIS} solver.
\iffalse
The optimal number of nodes for classification. The solver only starts preserving edges from three nodes. This observation is expected since with two nodes there will be only one edge. Starting with three nodes, we start to obtain a connected graph.

Independent of the type of feature used the number of edges obtained as a function of the number of nodes remained almost the same. Furthermore, it was seen that smaller subgraphs were more effective than larger subgraphs. The classification metrics remain the most important determinants of deciding the number of nodes. 
\fi
\section{Personality Classification}
The classification of personality traits was a methodologically challenging task. The personality traits are continuous in nature. A regression task was not formulated for these continuous variables since the regression task would be incompatible with the pipeline. The major focus of this thesis was to formulate a discriminative subgraph.

There are no population parameters that quantify the mean of a personality trait or its standard deviation. Personality traits are inferred mostly on the basis of questionnaires which introduces an abstraction in their use as a biomarker. It was difficult to predict personality since it depends on various factors which might not be elucidated by structural brain connectivity. Most studies using structural MRI data for the study of personality have failed in terms of replicability \citep{dubois2018resting}. 

According to our methodology, binning the continuous personality traits for a classification task lead to an information loss. An attempt was made to incorporate such a loss by using the Pearson correlation coefficient that captures linear relationships. The size of our training set of 141 subjects might have limited the ability of the pearson correlation coefficient to model a relationship between the features and a particular personality trait.

Theoretically, the Big 5 personality traits are supposed to be orthogonal and hence they were classified one trait at a time in our pipeline. However, the personality traits have been found to be correlated to one another \citep{blackburn2004big}. The classification accuracy with the \gls{MEWIS} might be different if a comprehensive model of personality is taken into account.
\iffalse
The reduced subgraphs obtained by using t-test and f-scores as edge weights lacked predictive power and often performed worse than the baseline experiments.
\fi
\section{Triviality of Graph Kernels}
% Non inclusion of graph kernels, why are they not applicable to our problem?
Graph kernels are kernels defined on graphs. They are often used for classification from networks structured data such as molecules. However, they are not suitable for classification from structural brain connectivity and were excluded from the analysis pipeline. This remainder of this section describes the nature of graph kernels and why they are ill-suited for the task described in this thesis.

Graph kernels measure the topological similarity between different networks of the same type. There are different types of graph kernels which are widely used in bioinformatics and chemoinformatics. For example subgraph matching kernels are widely used in chemoinformatics to identify similar molecules and the prediction of protein function \citep{nils2012}. However, they are not free of shortcomings. A limitation of graph kernels is their high computational complexity which makes them applicable only for small graphs. Most graph kernels are built on unweighted graphs and often rely on the assumption that all nodes in the graph are uniform.

For classification from structural brain connectivity it is required that specific characteristics of each node be taken into account, and to not lose out on information about the importance of connections \citep{jie2018sub}. In \autoref{fig:connectivity_matrix} the connectivity matrix consisted of 3486 features with each node labelled according to a lookup table (see Appendix). Using a graph kernel to determine pairwise similarities between subjects with the high number of features was computationally infeasible. In light of these reasons, graph kernels were not used for classification. The \gls{MEWIS} solver method proved to be well suited to the problem of feature selection in connectomics.

\iffalse
The unlabelled ones cannot get any information about brain networks since there is not meaning of comparing networks containing two different regions. Also computational complexity and density of brain networks leads to a bottleneck since computing kernel functions for such graphs is conclusive.  Isomorphism does not exist. 
. Using the existing framework the similarity of two networks cannot well reflect their topological characteristics.
\fi


\end{document}
